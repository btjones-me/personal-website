# Environment Configuration
DEBUG=false
LOG_LEVEL=INFO

# LLM Configuration
# Required: API key for Pydantic AI Gateway
PYDANTIC_AI_GATEWAY_API_KEY=
# Optional: Override default model (default: gateway/google-vertex:gemini-2.5-flash)
LLM_MODEL=
# Optional: Maximum input characters (default: 500)
LLM_MAX_INPUT_CHARS=500
# Optional: Maximum conversation turns (default: 10)
LLM_MAX_CONVERSATION_TURNS=10
# Optional: Rate limit per minute (default: 10)
LLM_RATE_LIMIT_PER_MINUTE=10
# Manual/expensive test flag to probe Gemini spend caps (off by default)
RUN_GEMINI_SPEND_CAP_TEST=0

# Logfire Configuration (for production deployment)
# Required in production: Token from 'uv run logfire auth --print-token'
LOGFIRE_TOKEN=
# Optional: Environment tag (e.g., production, staging)
LOGFIRE_ENVIRONMENT=
# Optional: Base URL for non-default Logfire region
LOGFIRE_BASE_URL=

# Railway Deployment Notes
# - PORT is automatically set by Railway (do not set manually)
# - Set all above variables in Railway dashboard under your service's "Variables" tab
# - For CI/CD: RAILWAY_SERVICE_ID and RAILWAY_TOKEN are GitHub secrets (not app env vars)

# Optional, set in config if not set here 
GA_MEASUREMENT_ID= 